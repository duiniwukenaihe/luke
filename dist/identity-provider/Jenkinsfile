#!groovy

// Default IdM image to use throughout the pipeline.
idmDefaultImage = ''

podTemplate(
    label: 'IdentityProvider-pipeline',
    containers: [
        // Used to build the container image
        containerTemplate(
            name: 'docker',
            image: 'docker',
            ttyEnabled: true,
            command: 'cat'
        ),
        containerTemplate(
            name: 'elasticsearch',
            image: 'docker.elastic.co/elasticsearch/elasticsearch:5.4.2',
            ttyEnabled: true,
            command: 'cat'
        ),
        // Used to download proper Sugarcrm build from honeycomb
        containerTemplate(
            name: 'python',
            image: 'python',
            ttyEnabled: true,
            command: 'cat'
        ),
        // Used to deploy service to k8s
        containerTemplate(
            name: 'kubectl',
            image: 'lachlanevenson/k8s-kubectl',
            ttyEnabled: true,
            command: 'cat'
        ),
    ],
    volumes: [
        // Required docker socket to be able to build container images. This will use
        // the docker service available on the k8s node directly.
        hostPathVolume(hostPath: '/var/run/docker.sock', mountPath: '/var/run/docker.sock')
    ]
) {
    node('IdentityProvider-pipeline') {
        ansiColor('xterm') {
            // Git commit hash. Is used for labeling docker containers.
            idmRevision = ''

            // Bag of IdM baked images where steps can retrieve from.
            idmImages = [:]

            stage('SCM IdentityProvider') {
                pullRequestStatus(description: 'SCM IdentityProvider') {
                    checkout scm
                    sh "git rev-parse --short HEAD > .git/commit-id"
                    idmRevision = readFile('.git/commit-id').trim()
                }
            }

            if (env.CHANGE_ID) {
                stage('Commit Message check') {
                    pullRequestStatus(description: 'Commit Message check') {
                        echo "Checking PR number in the commit message. It must include corresponding ticket number."
                        checkCommitTitleForJiraTicketNumber{}
                    }
                }
            }

            stage('Create Images') {
                pullRequestStatus(description: 'Create Images') {
                    container(name:'docker') {
                        parallel(
                                php56: { createIdmImage('php56') },
                                php71: { createIdmImage('php71') },
                        )

                        // set default image as long as it's baked.
                        idmDefaultImage = idmImages['php56']

                        // Push image for later usage by k8s. TODO: can we try to do it locally?
                        sh "docker push ${idmDefaultImage}"
                        sh "docker push ${idmImages['php71']}"
                    }
                }
            }

            stage('Code-standards check') {
                pullRequestStatus(description: 'Code-standards check') {
                    container(name:'docker') {
                        echo 'Running code-style only for minimal support version of PHP. PHP 5.6'
                        sh """
                        docker run --rm -it ${idmDefaultImage} /bin/bash -c \
                        'vendor/bin/php-cs-fixer fix \
                        --config=.php_cs.dist --diff --dry-run --verbose --using-cache=no \
                        --path-mode=intersection `git diff --name-only \
                        --diff-filter=ACMRTUXB origin/${env.CHANGE_TARGET} HEAD`'
                        """
                    }
                }
            }
        }
    }

    node('IdentityProvider-pipeline') {
        ansiColor('xterm') {
            stage('Unit tests') {
                pullRequestStatus(description: 'Unit tests') {
                    container(name:'docker') {
                        parallel(
                                php56: { runIdmPhpUnitSuite('php56', 'Unit Tests') },
                                php71: { runIdmPhpUnitSuite('php71', 'Unit Tests') },
                        )
                    }
                }
            }

            stage('Functional tests') {
                pullRequestStatus(description: 'Functional tests') {
                    container(name:'docker') {
                        parallel(
                                php56: { runIdmPhpUnitSuite('php56', 'Functional Tests') },
                                php71: { runIdmPhpUnitSuite('php71', 'Functional Tests') },
                        )
                    }
                }
            }
        }
    }

    node('IdentityProvider-pipeline') {
        ansiColor('xterm') {
            // k8s namespace for the entire pipeline.
            idmNS = "IdentityProvider-${env.BRANCH_NAME}".toLowerCase()

            mangoInstalledBaseImage = 'registry.sugarcrm.net/identity-provider/idm-mango-installed'

            stage('Fetch Mango build') {
                pullRequestStatus(description: 'Fetch Mango build') {
                    // We need to obtain IdentityProvider repo once again for this workspace.
                    checkout scm

                    container(name:'python') {
                        sh """#!/usr/bin/env python
import urllib.request, urllib.error, json, re

artifact = 'Build Ent'
user_feature_author = '${env.CHANGE_AUTHOR}'
pr_number_match = re.findall(r'\\b[A-Za-z]+[-_]?\\d+\\b', '${env.CHANGE_TITLE}')
user_feature_branch = pr_number_match[0] if len(pr_number_match) > 0 else ''
team_feature_author = 'avlasov'
team_feature_branch = 'idm_phase2'
deploy_feature_data_url = "http://honeycomb.sugarcrm.io/rest/v1/deploy/%s%s"
deploy_master_data_url = 'https://honeycomb.sugarcrm.io/rest/v1/builds/active'
build_url = "http://honeycomb.sugarcrm.io/download/deploy/{author}{branch}/{number}/SugarEnt-{version}{branch}.zip"
build_url_master = "https://honeycomb.sugarcrm.io/download/train/{version}/{number}/SugarEnt-{version}.zip"
out = "sugarcrm.zip"

def get_feature_build(author, branch):
    url = deploy_feature_data_url % (author, branch)
    with urllib.request.urlopen(url) as response:
        build_number = None
        data = json.loads(response.read().decode())

        if 'build_log' not in data or not data['build_log']:
            raise SystemExit('build_log information was not found for the latest deployment.')

        for task in data['build_log']:
            if task['status'] == artifact:
                if task['state'] == 'success':
                    build_number = data['build_number']
                else:
                    raise SystemExit('Latest Mango "%s" is not ready. Current status is "%s".'
                                     % (artifact, task['state']))

        if not build_number:
            raise SystemExit('There is no information for artifact "%s" for the latest deployment.' % artifact)

        tag = '%s%s_%s' % (author, branch, build_number)
        return build_url.format(author=author, branch=branch, version=data['version'], number=build_number), tag


def get_master_build(url):
    build_number = None
    with urllib.request.urlopen(url) as response:
        data = json.loads(response.read().decode())
        version, train_identifier = None, None

        for archive in data:
            if archive['mango_branch'] == 'master':
                build_number = archive['build_number']
                version = archive['version']
                break

        if not build_number or not version:
            raise SystemExit('There is no information for the latest master Mango build')

        return build_url_master.format(version=version, number=build_number), '%s_%s' % ('master', build_number)

# Main action.
try:
    build_url, tag = get_feature_build(user_feature_author, user_feature_branch)
except urllib.error.HTTPError:
    print('No user feature branch %s%s was found. Falling back to team feature Mango build.' %
          (user_feature_author, user_feature_branch))
    try:
        # For PRs not to master we are not interested in team feature branches.
        if '${env.CHANGE_TARGET}' != 'master': pass
        build_url, tag = get_feature_build(team_feature_author, team_feature_branch)
    except urllib.error.HTTPError:
        print('No team feature branch %s%s was found. Falling back to master Mango build.' %
              (team_feature_author, team_feature_branch))
        build_url, tag = get_master_build(deploy_master_data_url)

if build_url and tag:
    print('Fetching %s build...' % build_url)
    urllib.request.urlretrieve(build_url, out)
    with open('mango-build-number', 'w') as f:
        f.write(str(tag.replace('-', '').lower()))
else:
    raise SystemExit('No useful Mango build was found at all!')
                """
                    }
                }

                // Store the sugarcrm installed image name for later usage.
                mangoInstalledBaseImage = mangoInstalledBaseImage + ':' + readFile('mango-build-number').trim()
            }

            stage('Install SugarCRM') {
                pullRequestStatus(description: 'Install SugarCRM') {
                    try {
                        mangoBuild = "mango-built"
                        mangoInstallNet = "mango-install-net"
                        behatTestsEnvElastic = "behat-tests-env-elastic"

                        container(name:'docker') {
                            // Unpack downloaded Mango build into 'sugarcrm' directory inside bootstrap.
                            sh """
                            mkdir tests/docker/bootstrap/mango/sugarcrm
                            unzip sugarcrm.zip -d tests/docker/bootstrap/mango/sugarcrm
                            mv tests/docker/bootstrap/mango/sugarcrm/Sug*/* tests/docker/bootstrap/mango/sugarcrm/
                            rm sugarcrm.zip
                            """

                            // Ensure containers and networks we want to create do not exist.
                            cleanupMangoInstall()

                            sh """
                            echo 'Installing SugarCRM.'
                            docker network create --driver bridge ${mangoInstallNet}
                            docker run --name=${behatTestsEnvElastic} \
                            --network=${mangoInstallNet} -p 9200:9200 \
                            -e "http.host=0.0.0.0" -e "transport.host=127.0.0.1" -e "xpack.security.enabled=false" \
                            -d docker.elastic.co/elasticsearch/elasticsearch:5.4.2
                            """

                            withCredentials([string(credentialsId: 'SUGAR_LICENSE_KEY', variable: 'SUGAR_LICENSE_KEY')]) {
                                sh """
                                cd tests/docker/bootstrap/mango
                                docker build -t ${mangoBuild} .
                                docker run --name=${mangoBuild} --network=${mangoInstallNet} \
                                -e SUGAR_LICENSE_KEY="${env.SUGAR_LICENSE_KEY}" -p 80:80 -d ${mangoBuild}
                                sleep 10

                                echo 'Creating image with installed SugarCRM. Image: ${mangoInstalledBaseImage}'
                                docker exec -it ${mangoBuild} curl "http://localhost/install.php?goto=SilentInstall&cli=true"

                                docker commit ${mangoBuild} ${mangoInstalledBaseImage}
                                docker push ${mangoInstalledBaseImage}
                                """
                            }

                        }
                    } finally {
                        container(name:'docker') {
                            cleanupMangoInstall()
                        }
                    }
                }
            }
        }
    }

    try {
        node('IdentityProvider-pipeline') {
            ansiColor('xterm') {
                stage('Deploy environment for Behat') {
                    pullRequestStatus(description: 'Deploy environment for Behat') {
                        // Make sure code from IdentityProvider is available in this workspace.
                        checkout scm

                        container(name:'docker') {
                            sh """
                            cd tests/docker/openldap
                            docker build -t registry.sugarcrm.net/identity-provider/idm-open-ldap:latest .
                            docker push registry.sugarcrm.net/identity-provider/idm-open-ldap:latest
                            """
                        }

                        container(name:'docker') {
                            sh """
                            cd tests/docker/saml
                            docker build -t registry.sugarcrm.net/identity-provider/samlserver:latest .
                            docker push registry.sugarcrm.net/identity-provider/samlserver:latest
                            cd ../saml-test
                            docker build -t registry.sugarcrm.net/identity-provider/samlserver-test:latest .
                            docker push registry.sugarcrm.net/identity-provider/samlserver-test:latest
                            """
                        }

                        container(name:'kubectl') {
                            cleanupKubernetes()

                            retry(2) {
                                sh """
                                sleep 30
                                kubectl create namespace ${idmNS}
                                """
                            }

                            sh """
                            kubectl --namespace ${idmNS} create -f k8s/pipeline/selenium-deployment.yaml
                            kubectl --namespace ${idmNS} create -f k8s/pipeline/selenium-service.yaml

                            cat k8s/pipeline/idm-pod.yaml \
                            | sed -e "s~%%IDM_IMAGE%%~${idmDefaultImage}~g" \
                            | kubectl --namespace ${idmNS} create -f -

                            cat k8s/pipeline/mango/base-deployment.yaml \
                            | sed -e "s~%%MANGO_INSTALLED_IMAGE%%~${mangoInstalledBaseImage}~g" \
                            | kubectl --namespace ${idmNS} create -f -

                            kubectl --namespace ${idmNS} create -f k8s/pipeline/mango/base-services.yaml

                            kubectl --namespace ${idmNS} create configmap mango-config --from-file=k8s/pipeline/mango/config/

                            cat k8s/pipeline/mango/ldap-deployment.yaml \
                            | sed -e "s~%%MANGO_INSTALLED_IMAGE%%~${mangoInstalledBaseImage}~g" \
                            | kubectl --namespace ${idmNS} create -f -

                            kubectl --namespace ${idmNS} create -f k8s/pipeline/mango/ldap-service.yaml

                            cat k8s/pipeline/mango/saml-base-deployment.yaml \
                            | sed -e "s~%%MANGO_INSTALLED_IMAGE%%~${mangoInstalledBaseImage}~g" \
                            | kubectl --namespace ${idmNS} create -f -

                            kubectl --namespace ${idmNS} create -f k8s/pipeline/mango/saml-base-service.yaml

                            cat k8s/pipeline/mango/saml-same-window-deployment.yaml \
                            | sed -e "s~%%MANGO_INSTALLED_IMAGE%%~${mangoInstalledBaseImage}~g" \
                            | kubectl --namespace ${idmNS} create -f -
                            kubectl --namespace ${idmNS} create -f k8s/pipeline/mango/saml-same-window-service.yaml

                            cat k8s/pipeline/mango/saml-same-window-no-user-provision-deployment.yaml \
                            | sed -e "s~%%MANGO_INSTALLED_IMAGE%%~${mangoInstalledBaseImage}~g" \
                            | kubectl --namespace ${idmNS} create -f -
                            kubectl --namespace ${idmNS} create -f k8s/pipeline/mango/saml-same-window-no-user-provision-service.yaml

                            kubectl --namespace ${idmNS} create -f k8s/pipeline/ldap-deployment.yaml
                            kubectl --namespace ${idmNS} create -f k8s/pipeline/ldap-service.yaml

                            kubectl --namespace ${idmNS} create -f k8s/pipeline/saml-deployment.yaml
                            kubectl --namespace ${idmNS} create -f k8s/pipeline/saml-service.yaml
                            """
                        }
                    }
                }

                stage('Behat tests') {
                    pullRequestStatus(description: 'Behat tests') {
                        container(name:'kubectl') {
                            // Wait until all the required deployments are available.
                            retry(10) {
                                sh """
                                sleep 5
                                # debug information.
                                kubectl --namespace ${idmNS} get pod
                                kubectl --namespace ${idmNS} get services

                                kubectl --namespace ${idmNS} exec -it idm -- curl -XGET http://behat-tests-mango
                                kubectl --namespace ${idmNS} exec -it idm -- curl -XGET http://behat-tests-mango-ldap
                                kubectl --namespace ${idmNS} exec -it idm -- curl -XGET http://behat-tests-mango-saml-base
                                kubectl --namespace ${idmNS} exec -it idm -- curl -XGET http://behat-tests-mango-saml-same-window
                                kubectl --namespace ${idmNS} exec -it idm -- curl -XGET http://behat-tests-mango-saml-same-window-no-user-provision
                                kubectl --namespace ${idmNS} exec -it idm -- curl -XGET http://selenium:4444/wd/hub
                                kubectl --namespace ${idmNS} exec -it idm -- curl -XGET http://saml-server
                                """
                            }

                            parallel(
                                    default: {runBehatSuite('default', 'http://behat-tests-mango')},
                                    ldap: {runBehatSuite('ldap', 'http://behat-tests-mango-ldap')},
                                    saml: {runBehatSuite('saml', 'http://behat-tests-mango-saml-base')}
                            )
                        }
                    }
                }
            }
        }
    } finally {
        node('IdentityProvider-pipeline') {
            ansiColor('xterm') {
                stage('Cleanup') {
                    pullRequestStatus(description: 'Cleanup') {
                        container(name:'kubectl') {
                            retry(3) {
                                cleanupKubernetes()
                            }
                        }
                    }
                }
            }
        }
    }
}

// Creates IdentityProvider image based on given platform (matches Dockerfile extension by platform).
def createIdmImage(platform) {
    def idmImage = "registry.sugarcrm.net/identity-provider/idm:${idmRevision}_${platform}"
    sh "docker build -t ${idmImage} -f Dockerfile.${platform} ."
    idmImages[platform] = idmImage
}

// Runs specific PHPUnit tests suite in container based on particular image.
def runIdmPhpUnitSuite(platform, suite) {
    sh """
    docker run --rm -it ${idmImages[platform]} /bin/bash -c "./ci.sh && vendor/bin/phpunit --testsuite '${suite}'"
    """
}

// Removes previously created containers and networks used for Mango installation.
def cleanupMangoInstall() {
    sh """
    docker ps -a | grep ${mangoBuild} && docker rm -fv ${mangoBuild} || echo "Skip..."
    docker ps -a | grep ${behatTestsEnvElastic} && docker rm -fv ${behatTestsEnvElastic} || echo "Skip..."
    docker network ls | grep ${mangoInstallNet} && docker network rm ${mangoInstallNet} || echo "Skip..."
    """
}

// Removes k8s previously created pods, deployments, et al.
def cleanupKubernetes() {
    sh """
    kubectl get namespace | grep ${idmNS} && kubectl delete namespace ${idmNS} || echo "Skip..."
    """
}

// Runs specific Behat suite.
def runBehatSuite(suite, mangoUrl) {
    sh """
    kubectl --namespace ${idmNS} exec -it idm \
    -- tests/behat/behat.sh \
    -u ${mangoUrl} \
    -s ${suite} \
    -e selenium \
    -l ldap
    """
}
